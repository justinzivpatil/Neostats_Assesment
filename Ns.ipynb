{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j9Q78tZ-lUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf6fe89-b44d-4f85-8e71-dff7ca72a3e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline completed successfully.\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum as _sum, avg, when, lit, udf, sha2, regexp_replace\n",
        "# Step 1: Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"DataPipeline\").getOrCreate()\n",
        "\n",
        "# Step 2: Load Raw Data\n",
        "raw_data_path = \"/content/Sample_Data_For_Data_Engineering_UseCase (1).csv\"  # Update with actual path\n",
        "raw_df = spark.read.csv(raw_data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Data Validation\n",
        "# Check for missing critical columns\n",
        "required_columns = [\"OrderID\", \"Quantity\", \"Price\", \"CreditCardNumber\"]\n",
        "missing_columns = [col for col in required_columns if col not in raw_df.columns]\n",
        "if missing_columns:\n",
        "    raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
        "\n",
        "# Step 4: Data Transformation\n",
        "# Add Total_Sales column\n",
        "transformed_df = raw_df.withColumn(\"Total_Sales\", col(\"Quantity\") * col(\"Price\"))\n",
        "\n",
        "# Handle missing values\n",
        "transformed_df = transformed_df.fillna({\n",
        "    \"CustomerName\": \"Unknown\",\n",
        "    \"PhoneNumber\": \"000-000-0000\",\n",
        "    \"Location\": \"Unknown\",\n",
        "    \"Country\": \"Unknown\"\n",
        "}).na.drop(subset=[\"OrderID\", \"Price\", \"Quantity\"])\n",
        "\n",
        "# Group by Location and calculate metrics\n",
        "aggregated_df = (\n",
        "    transformed_df.groupBy(\"Location\")\n",
        "    .agg(\n",
        "        _sum(\"Total_Sales\").alias(\"Total_Sales\"),\n",
        "        avg(\"Total_Sales\").alias(\"Average_Order_Value\"),\n",
        "        _sum(\"Quantity\").alias(\"Total_Quantity\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 5: Handle PII Data\n",
        "# Anonymize CreditCardNumber\n",
        "pii_anonymized_df = transformed_df.withColumn(\n",
        "    \"CreditCard_Anonymized\", sha2(col(\"CreditCardNumber\"), 256)  # SHA-256 hashing\n",
        ").drop(\"CreditCardNumber\")  # Drop original column for security\n",
        "\n",
        "# Mask other sensitive data (e.g., phone numbers)\n",
        "pii_anonymized_df = pii_anonymized_df.withColumn(\n",
        "    \"Masked_PhoneNumber\", regexp_replace(col(\"PhoneNumber\"), r\".(?=.{4}$)\", \"*\")\n",
        ")\n",
        "\n",
        "# Step 6: Save Outputs\n",
        "# Save transformed data\n",
        "transformed_output_path = \"transformed_data\"\n",
        "transformed_df.write.mode(\"overwrite\").parquet(transformed_output_path)\n",
        "\n",
        "# Save aggregated data\n",
        "# Changed output path to a local directory. Update with your desired path.\n",
        "aggregated_output_path = \"aggregated_data\"\n",
        "aggregated_df.write.mode(\"overwrite\").parquet(aggregated_output_path)\n",
        "\n",
        "# Save anonymized PII data\n",
        "# Changed output path to a local directory. Update with your desired path.\n",
        "pii_output_path = \"anonymized_data\"\n",
        "pii_anonymized_df.write.mode(\"overwrite\").parquet(pii_output_path)\n",
        "\n",
        "print(\"Pipeline completed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qM4wG5fThFht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, regexp_replace\n",
        "\n",
        "# Mask credit card numbers\n",
        "sales_df = sales_df.withColumn(\n",
        "    \"Masked_CreditCardNumber\",\n",
        "    regexp_replace(col(\"CreditCardNumber\"), r\"\\d{12}\", \"****-****-****\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "ElrAIisl_SCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pycryptodome\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSUwCfGXCpbm",
        "outputId": "ac29850a-4f8c-4060-c3db-955d830ecd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome\n",
            "Successfully installed pycryptodome-3.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import StringType\n",
        "from Crypto.Cipher import AES\n",
        "import base64\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"EncryptCreditCard\").getOrCreate()\n",
        "\n",
        "# Sample data (replace with your actual DataFrame)\n",
        "data = [(\"1234567812345678\",), (\"8765432187654321\",)]\n",
        "columns = [\"CreditCardNumber\"]\n",
        "sales_df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Encryption setup\n",
        "def create_cipher():\n",
        "    key = b'sixteen byte key'  # Ensure 16-byte key\n",
        "    return AES.new(key, AES.MODE_ECB)\n",
        "\n",
        "# Encrypt function\n",
        "def encrypt_credit_card(card_number):\n",
        "    if card_number is None:\n",
        "        return None\n",
        "    padded_number = card_number.ljust(32)  # Pad to make it 32 bytes\n",
        "    cipher = create_cipher()  # Create cipher locally in the function\n",
        "    encrypted = cipher.encrypt(padded_number.encode())\n",
        "    return base64.b64encode(encrypted).decode()\n",
        "\n",
        "# Register UDF for encryption\n",
        "encrypt_udf = udf(encrypt_credit_card, StringType())\n",
        "\n",
        "# Apply encryption\n",
        "sales_df = sales_df.withColumn(\n",
        "    \"Encrypted_CreditCardNumber\",\n",
        "    encrypt_udf(col(\"CreditCardNumber\"))\n",
        ")\n",
        "\n",
        "# Show the results\n",
        "sales_df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAksvKKLCtr1",
        "outputId": "9b1fe806-2ff3-4ea9-c4e0-1d5795c58d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------------------------------+\n",
            "|CreditCardNumber|Encrypted_CreditCardNumber                  |\n",
            "+----------------+--------------------------------------------+\n",
            "|1234567812345678|6Q/X/fWXV/6SQO2dxUx1gJSmapPeeNYogG594rrVZL8=|\n",
            "|8765432187654321|+TbhuQfthIflnWFN89PV1ZSmapPeeNYogG594rrVZL8=|\n",
            "+----------------+--------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gYn7cgZ2CxV-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}